
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/10_augmentation.ipynb

from exp.nb_09c import *

make_rgb._order = 0

import random

def show_image(im, ax=None, figsize=(3, 3)):
  if ax is None:
    _, ax = plt.subplots(1, 1, figsize=figsize)
  ax.axis('off')
  ax.imshow(im.permute(1, 2, 0))

def show_batch(x, c=4, r=None, figsize=None):
  n = len(x)
  if r is None:
    r = int(math.ceil(n / c))
  if figsize is None:
    figsize = (3 * c, 3 * r)
  fig, axes = plt.subplots(r, c, figsize=figsize)
  for xi, ax in zip(x, axes.flat):
    show_image(xi, ax)

class PilTransform(Transform):
  _order = 11

class PilRandomFlip(PilTransform):
  def __init__(self, p=0.5):
    self.p = p

  def __call__(self, x):
    return x.transpose(PIL.Image.FLIP_LEFT_RIGHT) if random.random() < self.p else x

class PilRandomDihedral(PilTransform):
  def __init__(self, p=0.75):
    self.p = p * 7 / 8 # Little hack to get the 1/8 identity dihedral transform taken into account.

  def __call__(self, x):
    if random.random() > self.p:
      return x
    return x.transpose(random.randint(0, 6))

from random import randint

def process_sz(sz):
  sz = listify(sz)
  return tuple(sz if len(sz) == 2 else [sz[0], sz[0]])

def default_crop_size(w, h):
  return [w, w] if w < h else [h, h]

class GeneralCrop(PilTransform):
  def __init__(self, size, crop_size=None, resample=PIL.Image.BILINEAR):
    self.resample = resample
    self.size = process_sz(size)
    self.crop_size =  None if crop_size is None else process_sz(crop_size)

  def default_crop_size(self, w, h):
    return default_crop_size(w, h)

  def __call__(self, x):
    csize = self.default_crop_size(*x.size) if self.crop_size is None else self.crop_size
    return x.transform(self.size, PIL.Image.EXTENT, self.get_corners(*x.size, *csize), resample=self.resample)

  def get_corners(self, w, h):
    return (0, 0, w, h)

class CenterCrop(GeneralCrop):
  def __init__(self, size, scale=1.14, resample=PIL.Image.BILINEAR):
    super().__init__(size, resample=resample)
    self.scale = scale

  def default_crop_size(self, w, h):
    return [w / self.scale, h / self.scale]

  def get_corners(self, w, h, wc, hc):
    return ((w - wc) // 2, (h - hc) // 2, (w - wc) // 2 + wc, (h - hc) // 2 + hc)

class RandomResizedCrop(GeneralCrop):
  def __init__(self, size, scale=(0.08, 1.0), ratio=(3./4., 4./3.), resample=PIL.Image.BILINEAR):
    super().__init__(size, resample=resample)
    self.scale = scale
    self.ratio = ratio

  def get_corners(self, w, h, wc, hc):
    area = w * h
    # Tries 10 times to get a proper crop inside the image.
    for attemp in range(10):
      area = random.uniform(*self.scale) * area
      ratio = math.exp(random.uniform(math.log(self.ratio[0]), math.log(self.ratio[1])))
      new_w = int(round(math.sqrt(area * ratio)))
      new_h = int(round(math.sqrt(area / ratio)))
      if new_w <= w and new_h <= h:
        left = random.randint(0, w - new_w)
        top = random.randint(0, h - new_h)
        return (left, top, left + new_w, top + new_h)

    # Fallback to squish
    if w / h < self.ratio[0]:
      size = (w, int(w / self.ratio[0]))
    elif w / h > self.ratio[1]:
      size = (int(h * self.ratio[1]), h)
    else:
      size = (w, h)
    return ((w - size[0]) // 2, (h - size[1]) // 2, (w + size[0]) // 2, (h + size[1]) // 2)

from torch import FloatTensor, LongTensor

def find_coeffs(orig_pts, targ_pts):
  matrix = []
  # The equation we'll need to solve.
  for p1, p2 in zip(targ_pts, orig_pts):
    matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0] * p1[0], -p2[0] * p1[1]])
    matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1] * p1[0], -p2[1] * p1[1]])

  A = FloatTensor(matrix)
  B = FloatTensor(orig_pts).view(8, 1)
  # The 8 scalars we seek are solution for AX = B
  return list(torch.solve(B, A)[0][:, 0])

def warp(img, size, src_coords, resample=PIL.Image.BILINEAR):
  w, h = size
  targ_coords = ((0, 0), (0, h), (w, h), (w, 0))
  c = find_coeffs(src_coords, targ_coords)
  res = img.transform(size, PIL.Image.PERSPECTIVE, list(c), resample=resample)
  return res

def uniform(a, b):
  return a + (b - a) * random.random()

import numpy as np

def np_to_float(x):
  return torch.from_numpy(np.array(x, dtype=np.float32, copy=False)).permute(2, 0, 1).contiguous() / 255.

np_to_float._order = 30